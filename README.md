# üß† Narrative Intelligence Platform - Enhanced Version

Ein fortschrittliches System zur Analyse von Nachrichtendaten mit semantischem Clustering, Multi-dimensionaler Sentiment-Analyse und intelligenter Narrative-Erkennung.

## üöÄ Features

- **Dynamic Semantic Clustering**: Intelligente Gruppierung √§hnlicher Artikel
- **Multi-Dimensional Embeddings**: Verschiedene Embedding-Strategien f√ºr optimale Analyse
- **Advanced Sentiment & Emotion Analysis**: Sentiment, Emotion und Financial Sentiment
- **Context-Aware Keyword Extraction**: Dynamische und temporale Schl√ºsselwort-Erkennung
- **Interactive Dashboard**: Plotly-basierte Visualisierungen
- **Comprehensive Intelligence Reports**: Detaillierte Analyseberichte
- **Actor Network Analysis**: Journalisten- und Akteurs-Netzwerk-Analyse

## üìã Voraussetzungen

### Python Pakete
```bash
pip install pandas numpy matplotlib seaborn
pip install transformers sentence-transformers torch
pip install sklearn scikit-learn
pip install spacy plotly
pip install networkx hdbscan
```

### Optionale Pakete (f√ºr erweiterte Features)
```bash
pip install umap-learn textstat yake keybert textblob
pip install python-louvain python-igraph
```

### Spacy Modell
```bash
python -m spacy download en_core_web_sm
```

## üéØ Schnellstart

### Basis-Analyse
```bash
python robertaNC_turbo.py --csv "pfad/zu/deinen/daten.csv"
```

### Kleine Test-Analyse (schnell)
```bash
python robertaNC_turbo.py --csv "C:\Users\schwi\OneDrive\Desktop\bloomberg_news_1000.csv" --sample-size 50
```

### Analyse ohne Dashboard (f√ºr Entwicklung)
```bash
python robertaNC_turbo.py --csv "C:\Users\schwi\OneDrive\Desktop\bloomberg_news_1000.csv" --sample-size 50 --skip-dashboard
```

## üîß Command Line Parameter

### Erforderlich
- `--csv`: Pfad zur CSV-Datei mit den Nachrichtendaten

### Optional
- `--sample-size`: Maximale Anzahl Artikel f√ºr Analyse (Standard: 5000)
- `--min-cluster-size`: Minimale Cluster-Gr√∂√üe (Standard: 5)
- `--temporal-window-days`: Zeitfenster f√ºr temporales Clustering (Standard: 7)
- `--topic`: Keyword-Filter f√ºr Artikel (kann mehrfach verwendet werden)
- `--skip-dashboard`: Dashboard-Erstellung √ºberspringen (schneller f√ºr Tests)

## üìä Beispiel-Commands

### Schnelle Entwicklungs-Tests
```bash
# Sehr kleine Analyse f√ºr schnelle Tests
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv" --sample-size 20 --skip-dashboard

# Kleine Analyse mit Dashboard
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv" --sample-size 100

# Mittelgro√üe Analyse
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv" --sample-size 500
```

### Produktive Analysen
```bash
# Vollst√§ndige Analyse mit allen Features
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv"

# Gro√üe Analyse mit benutzerdefinierten Parametern
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv" --sample-size 2000 --min-cluster-size 3

# Temporale Analyse mit k√ºrzerem Zeitfenster
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv" --temporal-window-days 3
```

### Topic-spezifische Analysen
```bash
# Nur Artikel zu einem bestimmten Thema
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv" --topic "Tesla"

# Mehrere Keywords
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv" --topic "Tesla" "Stock" "Market"

# Themen-Analyse mit kleiner Stichprobe
python robertaNC_turbo.py --csv "bloomberg_news_1000.csv" --topic "AI" --sample-size 200
```

## üìÅ CSV-Format Anforderungen

Deine CSV-Datei sollte mindestens diese Spalten enthalten:
- `Date`: Datum der Artikel (YYYY-MM-DD Format)
- `Full_Text`: Volltext der Artikel
- `Headline`: Schlagzeilen (optional)
- `Journalists_List`: Liste der Journalisten (optional)

## üìà Output-Dateien

Nach der Analyse werden folgende Dateien erstellt:

### Visualisierungen
- `enhanced_narrative_dashboard.html`: Interaktives Dashboard

### Daten-Exports
- `enhanced_analysis_export.csv`: Hauptanalysedaten
- `cluster_analysis.csv`: Cluster-Informationen
- `actor_influence_export.csv`: Akteurs-Einfluss-Daten
- `narrative_summaries.csv`: Narrative Zusammenfassungen
- `keyword_analysis.csv`: Schl√ºsselwort-Analyse

## üèÉ‚Äç‚ôÇÔ∏è Analyse-Phasen

Das System durchl√§uft 9 Phasen:

1. **Data Loading & Preprocessing**: Daten laden und bereinigen
2. **Multi-Dimensional Embeddings**: Verschiedene Embedding-Strategien
3. **Dynamic Semantic Clustering**: Intelligentes Clustering
4. **Dynamic Keywords**: Kontext-bewusste Schl√ºsselwort-Extraktion
5. **Multi-Dimensional Sentiment**: Sentiment, Emotion, Financial Sentiment
6. **Enhanced Narrative Summaries**: Narrative Zusammenfassungen
7. **Enhanced Dashboard**: Interaktive Visualisierungen
8. **Situation Report**: Executive Briefing
9. **Enhanced Export**: Datenexport

## üõ†Ô∏è Entwicklung & Debugging

### Schnelle Test-Zyklen
```bash
# Minimaler Test (5-10 Sekunden)
python robertaNC_turbo.py --csv "daten.csv" --sample-size 10 --skip-dashboard

# Funktions-Test (30-60 Sekunden)
python robertaNC_turbo.py --csv "daten.csv" --sample-size 50 --skip-dashboard

# Vollst√§ndiger Test mit Dashboard (2-5 Minuten)
python robertaNC_turbo.py --csv "daten.csv" --sample-size 100
```

### Performance-Optimierung
- F√ºr schnelle Tests: `--sample-size 20-50` und `--skip-dashboard`
- F√ºr Entwicklung: `--sample-size 100-200`
- F√ºr Produktion: Ohne `sample-size` Begrenzung

## üîç Dashboard anpassen

Um das Dashboard zu √ºberspringen und eigene Visualisierungen zu erstellen:

1. **Analyse ohne Dashboard ausf√ºhren:**
   ```bash
   python robertaNC_turbo.py --csv "daten.csv" --skip-dashboard
   ```

2. **Exportierte Daten verwenden:**
   - Lade `enhanced_analysis_export.csv` f√ºr eigene Visualisierungen
   - Verwende die anderen CSV-Exports je nach Bedarf

3. **Eigenes Dashboard-Script erstellen:**
   ```python
   import pandas as pd
   import plotly.graph_objects as go
   
   # Analysedaten laden
   df = pd.read_csv("enhanced_analysis_export.csv")
   
   # Eigene Visualisierungen erstellen
   # ...
   ```

## ‚ùì Troubleshooting

### H√§ufige Probleme

**ModuleNotFoundError:**
```bash
pip install [fehlendes_paket]
```

**Memory-Probleme bei gro√üen Datens√§tzen:**
```bash
# Kleinere Sample-Size verwenden
python robertaNC_turbo.py --csv "daten.csv" --sample-size 1000
```

**Slow Performance:**
```bash
# Dashboard √ºberspringen f√ºr schnellere Tests
python robertaNC_turbo.py --csv "daten.csv" --skip-dashboard
```

### Logs und Debugging

Das System gibt detaillierte Fortschrittsmeldungen aus:
- üî• **PHASE X**: Aktuelle Analysephase
- ‚úÖ **Completed**: Erfolgreich abgeschlossene Schritte  
- ‚ö†Ô∏è **Warning**: Optionale Features nicht verf√ºgbar
- ‚ùå **Error**: Kritische Fehler

## üéØ Empfohlene Workflows

### Neue Daten erkunden
```bash
python robertaNC_turbo.py --csv "neue_daten.csv" --sample-size 100 --skip-dashboard
```

### Vollst√§ndige Analyse
```bash
python robertaNC_turbo.py --csv "daten.csv" --sample-size 2000
```

### Themen-spezifische Deep-Dive
```bash
python robertaNC_turbo.py --csv "daten.csv" --topic "KI" "OpenAI" --sample-size 500
```

---

## üèÜ Pro-Tips

1. **Entwicklung**: Immer mit `--skip-dashboard` und kleiner `--sample-size` beginnen
2. **Testing**: Verwende 50-100 Artikel f√ºr Funktions-Tests
3. **Produktion**: Ohne Limits f√ºr vollst√§ndige Insights
4. **Custom Dashboards**: Nutze die CSV-Exports f√ºr eigene Visualisierungen
5. **Performance**: Bei gro√üen Datens√§tzen schrittweise die Sample-Size erh√∂hen